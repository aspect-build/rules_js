"Convert pnpm lock file into starlark Bazel fetches"

load("@bazel_skylib//lib:paths.bzl", "paths")
load("@bazel_skylib//lib:dicts.bzl", "dicts")
load(":utils.bzl", "utils")
load(":transitive_closure.bzl", "translate_to_transitive_closure")
load(":starlark_codegen_utils.bzl", "starlark_codegen_utils")

_DOC = """Repository rule to generate npm_import rules from pnpm lock file.

The pnpm lockfile format includes all the information needed to define npm_import rules,
including the integrity hash, as calculated by the package manager.

For more details see, https://github.com/pnpm/pnpm/blob/main/packages/lockfile-types/src/index.ts.

Instead of manually declaring the `npm_imports`, this helper generates an external repository
containing a helper starlark module `repositories.bzl`, which supplies a loadable macro
`npm_repositories`. This macro creates an `npm_import` for each package.

The generated repository also contains BUILD files declaring targets for the packages
listed as `dependencies` or `devDependencies` in `package.json`, so you can declare
dependencies on those packages without having to repeat version information.

Bazel will only fetch the packages which are required for the requested targets to be analyzed.
Thus it is performant to convert a very large pnpm-lock.yaml file without concern for
users needing to fetch many unnecessary packages.

**Setup**

In `WORKSPACE`, call the repository rule pointing to your pnpm-lock.yaml file:

```starlark
load("@aspect_rules_js//npm:npm_import.bzl", "npm_translate_lock")

# Read the pnpm-lock.yaml file to automate creation of remaining npm_import rules
npm_translate_lock(
    # Creates a new repository named "@npm_deps"
    name = "npm_deps",
    pnpm_lock = "//:pnpm-lock.yaml",
    # Recommended attribute that also checks the .bazelignore file
    verify_node_modules_ignored = "//:.bazelignore",
)
```

Next, there are two choices, either load from the generated repo or check in the generated file.
The tradeoffs are similar to
[this rules_python thread](https://github.com/bazelbuild/rules_python/issues/608).

1. Immediately load from the generated `repositories.bzl` file in `WORKSPACE`.
This is similar to the
[`pip_parse`](https://github.com/bazelbuild/rules_python/blob/main/docs/pip.md#pip_parse)
rule in rules_python for example.
It has the advantage of also creating aliases for simpler dependencies that don't require
spelling out the version of the packages.
However it causes Bazel to eagerly evaluate the `npm_translate_lock` rule for every build,
even if the user didn't ask for anything JavaScript-related.

```starlark
# Following our example above, we named this "npm_deps"
load("@npm_deps//:repositories.bzl", "npm_repositories")

npm_repositories()
```

2. Check in the `repositories.bzl` file to version control, and load that instead.
This makes it easier to ship a ruleset that has its own npm dependencies, as users don't
have to install those dependencies. It also avoids eager-evaluation of `npm_translate_lock`
for builds that don't need it.
This is similar to the [`update-repos`](https://github.com/bazelbuild/bazel-gazelle#update-repos)
approach from bazel-gazelle.

In a BUILD file, use a rule like
[write_source_files](https://github.com/aspect-build/bazel-lib/blob/main/docs/write_source_files.md)
to copy the generated file to the repo and test that it stays updated:

```starlark
write_source_files(
    name = "update_repos",
    files = {
        "repositories.bzl": "@npm_deps//:repositories.bzl",
    },
)
```

Then in `WORKSPACE`, load from that checked-in copy or instruct your users to do so.
"""

_ATTRS = {
    "pnpm_lock": attr.label(
        doc = """The pnpm-lock.yaml file.""",
        mandatory = True,
    ),
    "patches": attr.string_list_dict(
        doc = """A map of package names or package names with their version (e.g., "my-package" or "my-package@v1.2.3")
        to a label list of patches to apply to the downloaded npm package. Paths in the patch
        file must start with `extract_tmp/package` where `package` is the top-level folder in
        the archive on npm. If the version is left out of the package name, the patch will be
        applied to every version of the npm package.""",
    ),
    "patch_args": attr.string_list_dict(
        doc = """A map of package names or package names with their version (e.g., "my-package" or "my-package@v1.2.3")
        to a label list arguments to pass to the patch tool. Defaults to -p0, but -p1 will
        usually be needed for patches generated by git. If patch args exists for a package
        as well as a package version, then the version-specific args will be appended to the args for the package.""",
    ),
    "custom_postinstalls": attr.string_dict(
        doc = """A map of package names or package names with their version (e.g., "my-package" or "my-package@v1.2.3")
        to a custom postinstall script to apply to the downloaded npm package after its lifecycle scripts runs.
        If the version is left out of the package name, the script will run on every version of the npm package. If
        a custom postinstall scripts exists for a package as well as for a specific version, the script for the versioned package
        will be appended with `&&` to the non-versioned package script.""",
    ),
    "prod": attr.bool(
        doc = """If true, only install dependencies""",
    ),
    "public_hoist_packages": attr.string_list_dict(
        doc = """A map of package names or package names with their version (e.g., "my-package" or "my-package@v1.2.3")
        to a list of Bazel packages in which to hoist the package to the top-level of the node_modules tree when linking.

        This is similar to setting https://pnpm.io/npmrc#public-hoist-pattern in an .npmrc file outside of Bazel, however,
        wild-cards are not yet supported and npm_translate_lock will fail if there are multiple versions of a package that
        are to be hoisted.""",
    ),
    "dev": attr.bool(
        doc = """If true, only install devDependencies""",
    ),
    "no_optional": attr.bool(
        doc = """If true, optionalDependencies are not installed""",
    ),
    "lifecycle_hooks_exclude": attr.string_list(
        doc = """A list of package names or package names with their version (e.g., "my-package" or "my-package@v1.2.3")
        to not run lifecycle hooks on""",
    ),
    "run_lifecycle_hooks": attr.bool(
        doc = """If true, runs preinstall, install and postinstall lifecycle hooks on npm packages if they exist""",
        default = True,
    ),
    "lifecycle_hooks_envs": attr.string_list_dict(
        doc = """Environment variables applied to the preinstall, install and postinstall lifecycle hooks on npm packages.
        The environment variables can be defined per package by package name or globally using "*".
        Variables are declared as key/value pairs of the form "key=value".
        For example:
        lifecycle_hooks_envs: {
            "*": ["GLOBAL_KEY1=value1", "GLOBAL_KEY2=value2"],
            "@foo/bar": ["PREBULT_BINARY=http://downloadurl"],
        }
        """,
    ),
    "lifecycle_hooks_execution_requirements": attr.string_list_dict(
        doc = """Execution requirements applied to the preinstall, install and postinstall lifecycle hooks on npm packages.
        The execution requirements can be defined per package by package name or globally using "*".
        For example:
        lifecycle_hooks_execution_requirements: {
            "*": ["requires-network"],
            "@foo/bar": ["no-sandbox"],
        }
        """,
    ),
    "verify_node_modules_ignored": attr.label(
        doc = """node_modules folders in the source tree should be ignored by Bazel.

        This points to a `.bazelignore` file to verify that all nested node_modules directories
        pnpm will create are listed.

        See https://github.com/bazelbuild/bazel/issues/8106
        """,
    ),
    "warn_on_unqualified_tarball_url": attr.bool(
        default = True,
    ),
}

def _process_lockfile(rctx):
    lockfile = utils.parse_pnpm_lock(rctx.read(rctx.path(rctx.attr.pnpm_lock)))
    return translate_to_transitive_closure(lockfile, rctx.attr.prod, rctx.attr.dev, rctx.attr.no_optional)

_NPM_IMPORT_TMPL = \
    """    npm_import(
        name = "{name}",
        root_package = "{root_package}",
        link_workspace = "{link_workspace}",
        link_packages = {link_packages},
        package = "{package}",
        version = "{version}",{maybe_integrity}{maybe_url}{maybe_deps}{maybe_transitive_closure}{maybe_patches}{maybe_patch_args}{maybe_run_lifecycle_hooks}{maybe_custom_postinstall}{maybe_lifecycle_hooks_env}{maybe_lifecycle_hooks_execution_requirements}
    )
"""

_BIN_TMPL = \
    """load("{repo_package_json_bzl}", _bin = "bin", _bin_factory = "bin_factory")
bin = _bin
bin_factory = _bin_factory
"""

_FP_STORE_TMPL = \
    """
    if is_root:
        _npm_package_store(
            name = "{virtual_store_root}/{{}}/{package}/0.0.0".format(name),
            src = "{npm_package_target}",
            package = "{package}",
            version = "0.0.0",
            deps = {deps},
            visibility = ["//visibility:public"],
            tags = ["manual"],
            use_declare_symlink = select({{
                "@aspect_rules_js//js/private:experimental_allow_unresolved_symlinks": True,
                "//conditions:default": False,
            }}),
        )"""

_FP_DIRECT_TMPL = \
    """
    for link_package in {link_packages}:
        if link_package == native.package_name():
            # terminal target for direct dependencies
            _npm_link_package_store(
                name = "{{}}/{name}".format(name),
                src = "//{root_package}:{virtual_store_root}/{{}}/{package}/0.0.0".format(name),
                visibility = ["//visibility:public"],
                tags = ["manual"],
                use_declare_symlink = select({{
                    "@aspect_rules_js//js/private:experimental_allow_unresolved_symlinks": True,
                    "//conditions:default": False,
                }}),
            )
            link_targets.append(":{{}}/{name}".format(name))

            # filegroup target that provides a single file which is
            # package directory for use in $(execpath) and $(rootpath)
            native.filegroup(
                name = "{{}}/{name}/dir".format(name),
                srcs = [":{{}}/{name}".format(name)],
                output_group = "{package_directory_output_group}",
                visibility = ["//visibility:public"],
                tags = ["manual"],
            )"""

_BZL_LIBRARY_TMPL = \
    """
bzl_library(
    name = "{name}",
    srcs = ["{src}"],
    deps = ["{dep}"],
    visibility = ["//visibility:public"],
)"""

_DEFS_BZL_FILENAME = "defs.bzl"
_REPOSITORIES_BZL_FILENAME = "repositories.bzl"
_PACKAGE_JSON_BZL_FILENAME = "package_json.bzl"

def _generated_by_lines(pnpm_lock_wksp, pnpm_lock):
    return [
        "\"@generated by @aspect_rules_js//npm/private:npm_translate_lock.bzl from pnpm lock file @{pnpm_lock_wksp}{pnpm_lock}\"".format(
            pnpm_lock_wksp = pnpm_lock_wksp,
            pnpm_lock = str(pnpm_lock),
        ),
        "",  # empty line after bzl docstring since buildifier expects this if this file is vendored in
    ]

def _link_package(root_package, import_path, rel_path = "."):
    link_package = paths.normalize(paths.join(root_package, import_path, rel_path))
    if link_package.startswith("../"):
        fail("Invalid link_package outside of the WORKSPACE: {}".format(link_package))
    if link_package == ".":
        link_package = ""
    return link_package

def _is_url(url):
    return url.find("://") != -1

def _gather_values_from_matching_names(keyed_lists, *names):
    result = []
    for name in names:
        if name:
            v = keyed_lists.get(name, [])
            if type(v) == "list":
                result.extend(v)
            else:
                result.append(v)
    return result

def _gen_npm_imports(lockfile, attr):
    "Converts packages from the lockfile to a struct of attributes for npm_import"

    if attr.prod and attr.dev:
        fail("prod and dev attributes cannot both be set to true")

    # root package is the directory of the pnpm_lock file
    root_package = attr.pnpm_lock.package

    # don't allow a pnpm lock file that isn't in the root directory of a bazel package
    if paths.dirname(attr.pnpm_lock.name):
        fail("pnpm-lock.yaml file must be at the root of a bazel package")

    packages = lockfile.get("packages")
    if not packages:
        fail("expected packages in processed lockfile")

    importers = lockfile.get("importers")
    if not importers:
        fail("expected importers in processed lockfile")

    result = []
    for package, package_info in packages.items():
        name = package_info.get("name")
        version = package_info.get("version")
        friendly_version = package_info.get("friendly_version")
        deps = package_info.get("dependencies")
        optional_deps = package_info.get("optionalDependencies")
        dev = package_info.get("dev")
        optional = package_info.get("optional")
        requires_build = package_info.get("requiresBuild")
        integrity = package_info.get("integrity")
        tarball = package_info.get("tarball")
        registry = package_info.get("registry")
        transitive_closure = package_info.get("transitiveClosure")

        if version.startswith("file:"):
            # this package is treated as a first-party dep
            continue

        if attr.prod and dev:
            # when prod attribute is set, skip devDependencies
            continue
        if attr.dev and not dev:
            # when dev attribute is set, skip (non-dev) dependencies
            continue
        if attr.no_optional and optional:
            # when no_optional attribute is set, skip optionalDependencies
            continue

        if not attr.no_optional:
            deps = dicts.add(optional_deps, deps)

        friendly_name = utils.friendly_name(name, friendly_version)
        unfriendly_name = utils.friendly_name(name, version)
        if unfriendly_name == friendly_name:
            # there is no unfriendly name for this package
            unfriendly_name = None

        # gather patches & patch args
        patches = _gather_values_from_matching_names(attr.patches, name, friendly_name, unfriendly_name)
        patch_args = _gather_values_from_matching_names(attr.patch_args, name, friendly_name, unfriendly_name)

        # gather custom postinstalls
        custom_postinstalls = _gather_values_from_matching_names(attr.custom_postinstalls, name, friendly_name, unfriendly_name)
        custom_postinstall = " && ".join([c for c in custom_postinstalls if c])

        repo_name = "%s__%s" % (attr.name, utils.bazel_name(name, version))
        if repo_name.startswith("aspect_rules_js.npm."):
            repo_name = repo_name[len("aspect_rules_js.npm."):]

        link_packages = {}

        for import_path, importer in importers.items():
            dependencies = importer.get("dependencies")
            if type(dependencies) != "dict":
                fail("expected dict of dependencies in processed importer '%s'" % import_path)
            link_package = _link_package(root_package, import_path)
            for dep_package, dep_version in dependencies.items():
                if dep_version.startswith("link:"):
                    continue
                if dep_version[0].isdigit():
                    maybe_package = utils.pnpm_name(dep_package, dep_version)
                elif dep_version.startswith("/"):
                    maybe_package = dep_version[1:]
                else:
                    maybe_package = dep_version
                if package == maybe_package:
                    # this package is a direct dependency at this import path
                    if link_package not in link_packages:
                        link_packages[link_package] = [dep_package]
                    else:
                        link_packages[link_package].append(dep_package)

        # check if this package should be hoisted via public_hoist_packages
        public_hoist_packages = _gather_values_from_matching_names(attr.public_hoist_packages, name, friendly_name, unfriendly_name)
        for public_hoist_package in public_hoist_packages:
            if public_hoist_package not in link_packages:
                link_packages[public_hoist_package] = [name]
            elif name not in link_packages[public_hoist_package]:
                link_packages[public_hoist_package].append(name)

        run_lifecycle_hooks = (
            requires_build and
            attr.run_lifecycle_hooks and
            name not in attr.lifecycle_hooks_exclude and
            friendly_name not in attr.lifecycle_hooks_exclude
        )

        lifecycle_hooks_env = _gather_values_from_matching_names(attr.lifecycle_hooks_envs, "*", name, friendly_name, unfriendly_name)
        lifecycle_hooks_execution_requirements = _gather_values_from_matching_names(attr.lifecycle_hooks_execution_requirements, "*", name, friendly_name, unfriendly_name)

        url = None
        if tarball:
            if _is_url(tarball):
                if registry and tarball.startswith("https://registry.npmjs.org/"):
                    url = registry + tarball[len("https://registry.npmjs.org/"):]
                else:
                    url = tarball
            else:
                # pnpm 6.x may omit the registry component from the tarball value when it is configured
                # via an .npmrc registry setting for the package. If there is a registry value, then use
                # that as the prefix. If there isn't then prefix with the default npm registry value and
                # suggest upgrading to a newer version pnpm.
                if not registry:
                    registry = "https://registry.npmjs.org/"

                    # buildifier: disable=print
                    if attr.warn_on_unqualified_tarball_url:
                        print("""

====================================================================================================
WARNING: The pnpm lockfile package entry for {} ({})
does not contain a fully qualified tarball URL or a registry setting to indiciate which registry to
use. Prefixing tarball url `{}`
with the default npm registry url `https://registry.npmjs.org/`.

If you are using an older version of pnpm such as 6.x, upgrading to 7.x or newer and
re-generating the lockfile should generate a fully qualified tarball URL for this package.

To disable this warning, set `warn_on_unqualified_tarball_url` to False in your
`npm_translate_lock` repository rule.
====================================================================================================

""".format(name, version, tarball))
                url = registry + tarball

        result.append(struct(
            custom_postinstall = custom_postinstall,
            deps = deps,
            integrity = integrity,
            link_packages = link_packages,
            name = repo_name,
            package = name,
            patch_args = patch_args,
            patches = patches,
            root_package = root_package,
            run_lifecycle_hooks = run_lifecycle_hooks,
            lifecycle_hooks_env = lifecycle_hooks_env,
            lifecycle_hooks_execution_requirements = lifecycle_hooks_execution_requirements,
            transitive_closure = transitive_closure,
            url = url,
            version = version,
        ))

    return result

def _normalize_bazelignore(lines):
    """Make bazelignore lines predictable

    - strip trailing slash so that users can have either of equivalent
        foo/node_modules or foo/node_modules/
    - strip leading ./ so users can have node_modules or ./node_modules
    """
    result = []
    for line in lines:
        if line.startswith("./"):
            result.append(line[2:].rstrip("/"))
        else:
            result.append(line.rstrip("/"))
    return result

def _verify_node_modules_ignored(rctx, importer_paths, bazelignore):
    bazelignore = _normalize_bazelignore(bazelignore.split("\n"))
    missing_ignores = []

    # The pnpm-lock.yaml file package needs to be prefixed on paths
    root = rctx.attr.pnpm_lock.package
    for i in importer_paths:
        if i == ".":
            expected = root
        else:
            expected = paths.normalize(paths.join(root, i))

        expected = paths.join(expected, "node_modules")
        if expected not in bazelignore:
            missing_ignores.append(expected)
    return missing_ignores

def _check_for_conflicting_public_links(npm_imports, public_hoist_packages):
    if not public_hoist_packages:
        return
    all_public_links = {}
    for _import in npm_imports:
        for link_package, link_names in _import.link_packages.items():
            if link_package not in all_public_links:
                all_public_links[link_package] = {}
            for link_name in link_names:
                if link_name not in all_public_links[link_package]:
                    all_public_links[link_package][link_name] = []
                all_public_links[link_package][link_name].append("{}@{}".format(_import.package, _import.version))
    for link_package, link_names in all_public_links.items():
        for link_name, link_packages in link_names.items():
            if len(link_packages) > 1:
                if link_name in public_hoist_packages:
                    msg = """\n\nInvalid public hoist configuration with multiple packages to hoist to `{}/node_modules/{}`: {}

Trying selecting a specific version of `{}` to hoist in public_hoist_packages. For example `{}`:

    ```
    public_hoist_packages = {{
        "{}": ["{}"]
    }}
    ```
""".format(
                        link_package,
                        link_name,
                        link_packages,
                        link_name,
                        link_packages[0],
                        link_packages[0],
                        link_package,
                    )
                else:
                    msg = """\n\nInvalid public hoist configuration with multiple packages to hoist to `{}/node_modules/{}`: {}

Check the public_hoist_packages attribute for duplicates.
""".format(
                        link_package,
                        link_name,
                        link_packages,
                    )
                fail(msg)

def _impl(rctx):
    lockfile = _process_lockfile(rctx)

    # root package is the directory of the pnpm_lock file
    root_package = rctx.attr.pnpm_lock.package

    generated_by_lines = _generated_by_lines(rctx.attr.pnpm_lock.workspace_name, rctx.attr.pnpm_lock)

    repositories_bzl = generated_by_lines + [
        """load("@aspect_rules_js//npm:npm_import.bzl", "npm_import")""",
        "",
        "def npm_repositories():",
        "    \"Generated npm_import repository rules corresponding to npm packages in @{pnpm_lock_wksp}{pnpm_lock}\"".format(
            pnpm_lock_wksp = str(rctx.attr.pnpm_lock.workspace_name),
            pnpm_lock = str(rctx.attr.pnpm_lock),
        ),
    ]

    packages = lockfile.get("packages")
    if not packages:
        fail("expected packages in processed lockfile")

    importers = lockfile.get("importers")
    if not importers:
        fail("expected importers in processed lockfile")

    importer_paths = importers.keys()

    if rctx.attr.verify_node_modules_ignored != None:
        missing_ignores = _verify_node_modules_ignored(rctx, importer_paths, rctx.read(rctx.path(rctx.attr.verify_node_modules_ignored)))
        if missing_ignores:
            fail("""\

ERROR: in verify_node_modules_ignored:
pnpm install will create nested node_modules, but not all of them are ignored by Bazel.
We recommend that all node_modules folders in the source tree be ignored,
to avoid Bazel printing confusing error messages.

Either add line(s) to {bazelignore}:

{fixes}

or disable this check by setting 'verify_node_modules_ignored = None' in `npm_translate_lock(name = "{repo}")`
                """.format(
                fixes = "\n".join(missing_ignores),
                bazelignore = rctx.attr.verify_node_modules_ignored,
                repo = rctx.name,
            ))

    link_packages = [_link_package(root_package, import_path) for import_path in importer_paths]

    defs_bzl_header = generated_by_lines + ["""# buildifier: disable=bzl-visibility
load("@aspect_rules_js//js:defs.bzl", _js_library = "js_library")"""]

    npm_imports = _gen_npm_imports(lockfile, rctx.attr)

    fp_links = {}
    rctx_files = {
        "BUILD.bazel": generated_by_lines + [
            """load("@bazel_skylib//:bzl_library.bzl", "bzl_library")""",
            "",
            "exports_files({})".format(starlark_codegen_utils.to_list_attr([
                _DEFS_BZL_FILENAME,
                _REPOSITORIES_BZL_FILENAME,
            ])),
        ],
    }

    # Look for first-party file: links in packages
    for package_info in packages.values():
        name = package_info.get("name")
        version = package_info.get("version")
        deps = package_info.get("dependencies")
        if version.startswith("file:"):
            dep_path = _link_package(root_package, version[len("file:"):])
            dep_key = "{}+{}".format(name, version)
            transitive_deps = {}
            for raw_package, raw_version in deps.items():
                if raw_version.startswith("link:") or raw_version.startswith("file:"):
                    dep_store_target = """"//{root_package}:{virtual_store_root}/{{}}/{package}/{version}".format(name)""".format(
                        root_package = root_package,
                        package = raw_package,
                        version = "0.0.0",
                        virtual_store_root = utils.virtual_store_root,
                    )
                elif raw_version.startswith("/"):
                    store_package, store_version = utils.parse_pnpm_name(raw_version[1:])
                    dep_store_target = """"//{root_package}:{virtual_store_root}/{{}}/{package}/{version}".format(name)""".format(
                        root_package = root_package,
                        package = store_package,
                        version = store_version,
                        virtual_store_root = utils.virtual_store_root,
                    )
                else:
                    dep_store_target = """"//{root_package}:{virtual_store_root}/{{}}/{package}/{version}".format(name)""".format(
                        root_package = root_package,
                        package = raw_package,
                        version = raw_version,
                        virtual_store_root = utils.virtual_store_root,
                    )
                if dep_store_target not in transitive_deps:
                    transitive_deps[dep_store_target] = [raw_package]
                else:
                    transitive_deps[dep_store_target].append(raw_package)

            # collapse link aliases lists into to acomma separated strings
            for dep_store_target in transitive_deps.keys():
                transitive_deps[dep_store_target] = ",".join(transitive_deps[dep_store_target])
            fp_links[dep_key] = {
                "package": name,
                "path": dep_path,
                "link_packages": {},
                "deps": transitive_deps,
            }

    # Look for first-party links in importers
    for import_path, importer in importers.items():
        dependencies = importer.get("dependencies")
        if type(dependencies) != "dict":
            fail("expected dict of dependencies in processed importer '%s'" % import_path)
        link_package = _link_package(root_package, import_path)
        for dep_package, dep_version in dependencies.items():
            if dep_version.startswith("file:"):
                dep_path = _link_package(root_package, dep_version[len("file:"):])
                dep_key = "{}+{}".format(dep_package, dep_version)
                if not dep_key in fp_links.keys():
                    fail("Expected to file: referenced package {} in first-party links".format(dep_key))
                fp_links[dep_key]["link_packages"][link_package] = []
            elif dep_version.startswith("link:"):
                dep_importer = paths.normalize(paths.join(import_path, dep_version[len("link:"):]))
                dep_path = _link_package(root_package, import_path, dep_version[len("link:"):])
                dep_key = "{}+{}".format(dep_package, dep_path)
                if dep_key in fp_links.keys():
                    fp_links[dep_key]["link_packages"][link_package] = []
                else:
                    transitive_deps = {}
                    raw_deps = {}
                    if dep_importer in importers.keys():
                        raw_deps = importers.get(dep_importer).get("dependencies")
                    for raw_package, raw_version in raw_deps.items():
                        if raw_version.startswith("link:") or raw_version.startswith("file:"):
                            dep_store_target = """"//{root_package}:{virtual_store_root}/{{}}/{package}/{version}".format(name)""".format(
                                root_package = root_package,
                                package = raw_package,
                                version = "0.0.0",
                                virtual_store_root = utils.virtual_store_root,
                            )
                        elif raw_version.startswith("/"):
                            store_package, store_version = utils.parse_pnpm_name(raw_version[1:])
                            dep_store_target = """"//{root_package}:{virtual_store_root}/{{}}/{package}/{version}".format(name)""".format(
                                root_package = root_package,
                                package = store_package,
                                version = store_version,
                                virtual_store_root = utils.virtual_store_root,
                            )
                        else:
                            dep_store_target = """"//{root_package}:{virtual_store_root}/{{}}/{package}/{version}".format(name)""".format(
                                root_package = root_package,
                                package = raw_package,
                                version = raw_version,
                                virtual_store_root = utils.virtual_store_root,
                            )
                        if dep_store_target not in transitive_deps:
                            transitive_deps[dep_store_target] = [raw_package]
                        else:
                            transitive_deps[dep_store_target].append(raw_package)

                    # collapse link aliases lists into to acomma separated strings
                    for dep_store_target in transitive_deps.keys():
                        transitive_deps[dep_store_target] = ",".join(transitive_deps[dep_store_target])
                    fp_links[dep_key] = {
                        "package": dep_package,
                        "path": dep_path,
                        "link_packages": {link_package: []},
                        "deps": transitive_deps,
                    }

    if fp_links:
        defs_bzl_header.append("""load("@aspect_rules_js//npm/private:npm_link_package_store.bzl", _npm_link_package_store = "npm_link_package_store")
load("@aspect_rules_js//npm/private:npm_package_store.bzl", _npm_package_store = "npm_package_store")""")

    defs_bzl_body = [
        """def npm_link_all_packages(name = "node_modules", imported_links = []):
    \"\"\"Generated list of npm_link_package() target generators and first-party linked packages corresponding to the packages in @{pnpm_lock_wksp}{pnpm_lock}

    Args:
        name: name of catch all target to generate for all packages linked
        imported_links: optional list link functions from manually imported packages
            that were fetched with npm_import rules,

            For example,

            ```
            load("@npm//:defs.bzl", "npm_link_all_packages")
            load("@npm_meaning-of-life__links//:defs.bzl", npm_link_meaning_of_life = "npm_link_imported_package")

            npm_link_all_packages(
                name = "node_modules",
                imported_links = [
                    npm_link_meaning_of_life,
                ],
            )```
    \"\"\"

    root_package = "{root_package}"
    link_packages = {link_packages}
    is_root = native.package_name() == root_package
    link = native.package_name() in link_packages
    if not is_root and not link:
        msg = "The npm_link_all_packages() macro loaded from {defs_bzl_file} and called in bazel package '%s' may only be called in the bazel package(s) corresponding to the root package '{root_package}' and packages [{link_packages_comma_separated}]" % native.package_name()
        fail(msg)
    link_targets = []
    scope_targets = {{}}

    for link_fn in imported_links:
        new_link_targets, new_scope_targets = link_fn(name)
        link_targets.extend(new_link_targets)
        for _scope, _targets in new_scope_targets.items():
            scope_targets[_scope] = scope_targets[_scope] + _targets if _scope in scope_targets else _targets
""".format(
            pnpm_lock_wksp = str(rctx.attr.pnpm_lock.workspace_name),
            pnpm_lock = str(rctx.attr.pnpm_lock),
            root_package = root_package,
            link_packages = str(link_packages),
            link_packages_comma_separated = "'" + "', '".join(link_packages) + "'" if len(link_packages) else "",
            defs_bzl_file = "@{}//:{}".format(rctx.name, _DEFS_BZL_FILENAME),
        ),
    ]

    # check all links and fail if there are duplicates which can happen with public hoisting
    _check_for_conflicting_public_links(npm_imports, rctx.attr.public_hoist_packages)

    stores_bzl = []
    links_bzl = {}
    for (i, _import) in enumerate(npm_imports):
        maybe_integrity = """
        integrity = "%s",""" % _import.integrity if _import.integrity else ""
        maybe_url = """
        url = "%s",""" % _import.url if _import.url else ""
        maybe_deps = ("""
        deps = %s,""" % starlark_codegen_utils.to_dict_attr(_import.deps, 2)) if len(_import.deps) > 0 else ""
        maybe_transitive_closure = ("""
        transitive_closure = %s,""" % starlark_codegen_utils.to_dict_list_attr(_import.transitive_closure, 2)) if len(_import.transitive_closure) > 0 else ""
        maybe_patches = ("""
        patches = %s,""" % _import.patches) if len(_import.patches) > 0 else ""
        maybe_patch_args = ("""
        patch_args = %s,""" % _import.patch_args) if len(_import.patches) > 0 and len(_import.patch_args) > 0 else ""
        maybe_custom_postinstall = ("""
        custom_postinstall = \"%s\",""" % _import.custom_postinstall) if _import.custom_postinstall else ""
        maybe_run_lifecycle_hooks = ("""
        run_lifecycle_hooks = True,""") if _import.run_lifecycle_hooks else ""
        maybe_lifecycle_hooks_env = ("""
        lifecycle_hooks_env = %s,""" % _import.lifecycle_hooks_env) if _import.run_lifecycle_hooks and _import.lifecycle_hooks_env else ""
        maybe_lifecycle_hooks_execution_requirements = ("""
        lifecycle_hooks_execution_requirements = %s,""" % _import.lifecycle_hooks_execution_requirements) if _import.run_lifecycle_hooks and _import.lifecycle_hooks_execution_requirements else ""

        repositories_bzl.append(_NPM_IMPORT_TMPL.format(
            link_packages = starlark_codegen_utils.to_dict_attr(_import.link_packages, 2, quote_value = False),
            link_workspace = rctx.attr.pnpm_lock.workspace_name,
            maybe_custom_postinstall = maybe_custom_postinstall,
            maybe_deps = maybe_deps,
            maybe_integrity = maybe_integrity,
            maybe_patch_args = maybe_patch_args,
            maybe_patches = maybe_patches,
            maybe_run_lifecycle_hooks = maybe_run_lifecycle_hooks,
            maybe_lifecycle_hooks_env = maybe_lifecycle_hooks_env,
            maybe_lifecycle_hooks_execution_requirements = maybe_lifecycle_hooks_execution_requirements,
            maybe_transitive_closure = maybe_transitive_closure,
            maybe_url = maybe_url,
            name = _import.name,
            package = _import.package,
            root_package = _import.root_package,
            version = _import.version,
        ))

        if _import.link_packages:
            defs_bzl_header.append(
                """load("@{repo_name}{links_repo_suffix}//:defs.bzl", link_{i} = "npm_link_imported_package_store", store_{i} = "npm_imported_package_store")""".format(
                    i = i,
                    repo_name = _import.name,
                    links_repo_suffix = utils.links_repo_suffix,
                ),
            )
        else:
            defs_bzl_header.append(
                """load("@{repo_name}{links_repo_suffix}//:defs.bzl", store_{i} = "npm_imported_package_store")""".format(
                    i = i,
                    repo_name = _import.name,
                    links_repo_suffix = utils.links_repo_suffix,
                ),
            )

        stores_bzl.append("""        store_{i}(name = "{{}}/{name}".format(name))""".format(
            i = i,
            name = _import.package,
        ))
        for link_package, _link_aliases in _import.link_packages.items():
            link_aliases = _link_aliases or [_import.package]
            for link_alias in link_aliases:
                if link_package not in links_bzl:
                    links_bzl[link_package] = []
                links_bzl[link_package].append("""            link_targets.append(link_{i}(name = "{{}}/{name}".format(name)))""".format(
                    i = i,
                    name = link_alias,
                ))
                if len(link_alias.split("/", 1)) > 1:
                    package_scope = link_alias.split("/", 1)[0]
                    links_bzl[link_package].append("""            scope_targets["{package_scope}"] = scope_targets["{package_scope}"] + [link_targets[-1]] if "{package_scope}" in scope_targets else [link_targets[-1]]""".format(
                        package_scope = package_scope,
                    ))
        pkgs = lockfile.get("packages").values()
        for link_package in _import.link_packages.keys():
            if pkgs[i].get("hasBin"):
                build_file_path = paths.normalize(paths.join(link_package, "BUILD.bazel"))
                if build_file_path not in rctx_files.keys():
                    rctx_files[build_file_path] = generated_by_lines + [
                        """load("@bazel_skylib//:bzl_library.bzl", "bzl_library")""",
                    ]
                rctx_files[build_file_path].append(_BZL_LIBRARY_TMPL.format(
                    name = _import.package,
                    src = ":" + paths.join(_import.package, _PACKAGE_JSON_BZL_FILENAME),
                    dep = "@{repo_name}//{link_package}:{package_name}".format(
                        repo_name = _import.name,
                        link_package = link_package,
                        package_name = link_package.split("/")[-1] or _import.package.split("/")[-1],
                    ),
                ))
                package_json_bzl_file_path = paths.normalize(paths.join(link_package, _import.package, _PACKAGE_JSON_BZL_FILENAME))
                repo_package_json_bzl = "@{repo_name}//{link_package}:{package_json_bzl}".format(
                    repo_name = _import.name,
                    link_package = link_package,
                    package_json_bzl = _PACKAGE_JSON_BZL_FILENAME,
                )
                rctx.file(package_json_bzl_file_path, "\n".join([
                    _BIN_TMPL.format(
                        repo_package_json_bzl = repo_package_json_bzl,
                    ),
                ]))

    defs_bzl_body.append("""    if is_root:""")
    defs_bzl_body.extend(stores_bzl)

    defs_bzl_body.append("""    if link:""")
    for link_package, bzl in links_bzl.items():
        defs_bzl_body.append("""        if native.package_name() == "{}":""".format(link_package))
        defs_bzl_body.extend(bzl)

    for fp_link in fp_links.values():
        fp_package = fp_link.get("package")
        fp_path = fp_link.get("path")
        fp_link_packages = fp_link.get("link_packages")
        fp_deps = fp_link.get("deps")
        fp_bazel_name = utils.bazel_name(fp_package, fp_path)
        fp_target = "//{}:{}".format(fp_path, paths.basename(fp_path))

        defs_bzl_body.append(_FP_STORE_TMPL.format(
            bazel_name = fp_bazel_name,
            deps = starlark_codegen_utils.to_dict_attr(fp_deps, 3, quote_key = False),
            npm_package_target = fp_target,
            package = fp_package,
            virtual_store_root = utils.virtual_store_root,
        ))

        defs_bzl_body.append(_FP_DIRECT_TMPL.format(
            bazel_name = fp_bazel_name,
            link_packages = fp_link_packages.keys(),
            name = fp_package,
            package = fp_package,
            package_directory_output_group = utils.package_directory_output_group,
            root_package = root_package,
            virtual_store_root = utils.virtual_store_root,
        ))

        if len(fp_package.split("/", 1)) > 1:
            package_scope = fp_package.split("/", 1)[0]
            defs_bzl_body.append("""            scope_targets["{package_scope}"] = scope_targets["{package_scope}"] + [link_targets[-1]] if "{package_scope}" in scope_targets else [link_targets[-1]]""".format(
                package_scope = package_scope,
            ))

    # Generate catch all & scoped npm_linked_packages target
    defs_bzl_body.append("""
    for scope, scoped_targets in scope_targets.items():
        _js_library(
            name = "{}/{}".format(name, scope),
            srcs = scoped_targets,
            tags = ["manual"],
            visibility = ["//visibility:public"],
        )

    _js_library(
        name = name,
        srcs = link_targets,
        tags = ["manual"],
        visibility = ["//visibility:public"],
    )""")

    rctx.file(_DEFS_BZL_FILENAME, "\n".join(defs_bzl_header + [""] + defs_bzl_body + [""]))
    rctx.file(_REPOSITORIES_BZL_FILENAME, "\n".join(repositories_bzl))
    for filename, contents in rctx_files.items():
        rctx.file(filename, "\n".join(contents))

npm_translate_lock = struct(
    doc = _DOC,
    implementation = _impl,
    attrs = _ATTRS,
    gen_npm_imports = _gen_npm_imports,
)

npm_translate_lock_testonly = struct(
    testonly_process_lockfile = _process_lockfile,
    verify_node_modules_ignored = _verify_node_modules_ignored,
)
